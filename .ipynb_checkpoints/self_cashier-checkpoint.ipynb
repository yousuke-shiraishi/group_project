{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __Data Augmentation__\n",
    "- Dog & Cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_path = 'image_folder/images/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n",
    "\n",
    "\n",
    "def augmentation(dir_path, initial_letter_of_file='w', augment_num=3):\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    note : 指定ディレクトリ内の,指定頭文字で始まるファイルを指定枚数オーグメントする\n",
    "    ----------\n",
    "    dir_path : フォルダパス\n",
    "    initial_letter : augmentしたいファイル名の頭文字\n",
    "    aument_num : augmentしたい枚数\n",
    "    ----------\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    files_name = [f for f in listdir(my_path) if isfile(join(my_path, f))]\n",
    "    files_name.remove('.DS_Store')\n",
    "    \n",
    "    \n",
    "    datagen = ImageDataGenerator(rotation_range=40,\n",
    "                             width_shift_range=0.2,\n",
    "                             height_shift_range=0.2,\n",
    "                             shear_range=0.2,\n",
    "                             zoom_range=0.2,\n",
    "                             horizontal_flip=True,\n",
    "                             fill_mode='nearest'\n",
    "    )\n",
    "    \n",
    "    \n",
    "    for i, file in enumerate(files_name):\n",
    "        img = load_img(dir_path + file)\n",
    "        x = img_to_array(img)\n",
    "        x = x.reshape((1,) + x.shape) \n",
    "\n",
    "        if file[0] == initial_letter_of_file:\n",
    "            i = 0\n",
    "            for batch in datagen.flow(x, save_to_dir=dir_path, save_prefix=initial_letter_of_file, save_format=\"jpg\"):\n",
    "                i += 1\n",
    "                if i > augment_num:\n",
    "                    break\n",
    "\n",
    "        else:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "cannot identify image file 'image_folder/images/coffee-20.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-f2ca7e48f570>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0maugmentation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmy_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0maugmentation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmy_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mupdated_files_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmy_path\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmy_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-26-6f2491796109>\u001b[0m in \u001b[0;36maugmentation\u001b[0;34m(dir_path, initial_letter_of_file, augment_num)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg_to_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras_preprocessing/image/utils.py\u001b[0m in \u001b[0;36mload_img\u001b[0;34m(path, grayscale, color_mode, target_size, interpolation)\u001b[0m\n\u001b[1;32m    102\u001b[0m         raise ImportError('Could not import PIL.Image. '\n\u001b[1;32m    103\u001b[0m                           'The use of `array_to_img` requires PIL.')\n\u001b[0;32m--> 104\u001b[0;31m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpil_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcolor_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'grayscale'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'L'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode)\u001b[0m\n\u001b[1;32m   2620\u001b[0m         \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2621\u001b[0m     raise IOError(\"cannot identify image file %r\"\n\u001b[0;32m-> 2622\u001b[0;31m                   % (filename if filename else fp))\n\u001b[0m\u001b[1;32m   2623\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2624\u001b[0m \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: cannot identify image file 'image_folder/images/coffee-20.jpg'"
     ]
    }
   ],
   "source": [
    "augmentation(my_path, 'c')\n",
    "augmentation(my_path, 'w')\n",
    "\n",
    "updated_files_name = [f for f in listdir(my_path) if isfile(join(my_path, f))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yuyafujisaki/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "  \n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "cannot identify image file 'image_folder/images/coffee-20.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-017c6afde211>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmisc\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mimread\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"image_folder/images/coffee-20.jpg\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/numpy/lib/utils.py\u001b[0m in \u001b[0;36mnewfunc\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m     99\u001b[0m             \u001b[0;34m\"\"\"`arrayrange` is deprecated, use `arange` instead!\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m             \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdepdoc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDeprecationWarning\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0mnewfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_set_function_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnewfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mold_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/scipy/misc/pilutil.py\u001b[0m in \u001b[0;36mimread\u001b[0;34m(name, flatten, mode)\u001b[0m\n\u001b[1;32m    162\u001b[0m     \"\"\"\n\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m     \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfromimage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflatten\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode)\u001b[0m\n\u001b[1;32m   2620\u001b[0m         \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2621\u001b[0m     raise IOError(\"cannot identify image file %r\"\n\u001b[0;32m-> 2622\u001b[0;31m                   % (filename if filename else fp))\n\u001b[0m\u001b[1;32m   2623\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2624\u001b[0m \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: cannot identify image file 'image_folder/images/coffee-20.jpg'"
     ]
    }
   ],
   "source": [
    "from scipy.misc import imread\n",
    "print(imread(\"image_folder/images/coffee-20.jpg\").shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(0)\n",
    "random.shuffle(updated_files_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __前処理__\n",
    "- ラベルデータの保存\n",
    "- resize\n",
    "- test_data, val_dataへの分割\n",
    "- Dog - 1, Cat - 0\n",
    "- ディレクトリの作成\n",
    "    - catsvsdogs / images / train / dogs\n",
    "    - catsvsdogs / images / train / cats\n",
    "    - catsvsdogs / images / val / dogs\n",
    "    - catsvsdogs / images / val / cats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __保存用ディレクトリの作成__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "class1_dir_train = 'image_folder/train/class1/'\n",
    "class1_dir_val = 'image_folder/test/class1/'\n",
    "class2_dir_train = 'image_folder/train/class2/'\n",
    "class2_dir_val = 'image_folder/test/class2/'\n",
    "\n",
    "def make_dir(directory):\n",
    "    if os.path.exists(directory):\n",
    "        shutil.rmtree(directory)\n",
    "    os.makedirs(directory)\n",
    "    \n",
    "make_dir(class1_dir_train)\n",
    "make_dir(class1_dir_val)\n",
    "make_dir(class2_dir_train)\n",
    "make_dir(class2_dir_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __データのふるい分け、分割__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import sys\n",
    "import shutil\n",
    "\n",
    "\n",
    "def train_test_split(files_name, class_1='w', class_2='c', train_size=0.8):\n",
    "    \n",
    "    \"\"\"\n",
    "    note : 画像フォルダから、指定クラスを、指定割合でtrain_sprit\n",
    "    ----------\n",
    "    class_1 : クラス名（今回はdog）\n",
    "    class_2 : クラス名（今回はcat）\n",
    "    train_size : 分割したい割合\n",
    "    ----------\n",
    "    \"\"\"\n",
    "    \n",
    "    class_1_count = 0\n",
    "    class_2_count = 0\n",
    "    \n",
    "    each_class_size = len(files_name) // 2\n",
    "    \n",
    "    train_size = each_class_size * train_size\n",
    "    test_size = each_class_size - train_size\n",
    "    \n",
    "    training_images = []\n",
    "    training_labels = []\n",
    "    test_images = []\n",
    "    test_labels = []\n",
    "    \n",
    "    size=200\n",
    "    \n",
    "    for i, file in enumerate(files_name):\n",
    "        \n",
    "        if files_name[i][0] == class_1:\n",
    "            class_1_count += 1\n",
    "            image = cv2.imread(my_path + file)\n",
    "            image = cv2.resize(image, (size, size), interpolation = cv2.INTER_AREA)\n",
    "            if class_1_count <= train_size:\n",
    "                training_images.append(image)\n",
    "                training_labels.append(1)\n",
    "                cv2.imwrite(class1_dir_train + class_1 + str(class_1_count) + '.jpg', image)\n",
    "            if class_1_count > train_size and class_1_count <= train_size + test_size:\n",
    "                test_images.append(image)\n",
    "                test_labels.append(1)\n",
    "                cv2.imwrite(class1_dir_val + class_1 + str(class_1_count) + '_' + '.jpg', image)\n",
    "\n",
    "        if files_name[i][0] == class_2:\n",
    "            class_2_count += 1\n",
    "            image = cv2.imread(my_path + file)\n",
    "            image = cv2.resize(image, (size, size), interpolation = cv2.INTER_AREA)\n",
    "            if class_2_count <= train_size:\n",
    "                training_images.append(image)\n",
    "                training_labels.append(0)\n",
    "                cv2.imwrite(class2_dir_train + class_2 + str(class_2_count) + '.jpg', image)\n",
    "            if class_2_count > train_size and class_2_count <= train_size + test_size:\n",
    "                test_images.append(image)\n",
    "                test_labels.append(0)\n",
    "                cv2.imwrite(class2_dir_val + class_2 + str(class_2_count) + '_' + '.jpg', image)\n",
    "                \n",
    "    return training_images, training_labels, test_images, test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_images, training_labels, test_images, test_labels = train_test_split(updated_files_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __Kerasが対応するファイル型に変換__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez('wil_vs_cof_training_data.npz', np.array(training_images))\n",
    "np.savez('wil_vs_cof_training_labels.npz', np.array(training_labels))\n",
    "np.savez('wil_vs_cof_test_data.npz', np.array(test_images))\n",
    "np.savez('wil_vs_cof_test_labels.npz', np.array(test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def load_data_training_and_test(datasetname):\n",
    "    npzfile = np.load(datasetname + \"_training_data.npz\")\n",
    "    train = npzfile[\"arr_0\"]\n",
    "    \n",
    "    npzfile = np.load(datasetname + \"_training_labels.npz\")\n",
    "    train_labels = npzfile[\"arr_0\"]\n",
    "    \n",
    "    npzfile = np.load(datasetname + \"_test_data.npz\")\n",
    "    test = npzfile[\"arr_0\"]\n",
    "    \n",
    "    npzfile = np.load(datasetname + \"_test_labels.npz\")\n",
    "    test_labels = npzfile[\"arr_0\"]\n",
    "    \n",
    "    return (train, train_labels), (test, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for i in range(1, 11):\n",
    "    random = np.random.randint(0, len(training_images))\n",
    "    cv2.imshow(\"image_\" + str(i), training_images[random])\n",
    "    if training_labels[random] == 0:\n",
    "        print(str(i) + \"- Cat\")\n",
    "    else:\n",
    "        print(str(i) + \"- Dog\")\n",
    "        \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __データの前処理__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = load_data_training_and_test(\"wil_vs_cof\")\n",
    "\n",
    "y_train = y_train.reshape(y_train.shape[0], 1)\n",
    "y_test = y_test.reshape(y_test.shape[0], 1)\n",
    "\n",
    "X_train = X_train.astype(\"float32\")\n",
    "X_test = X_test.astype(\"float32\")\n",
    "\n",
    "X_train /= 255\n",
    "X_test /= 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __学習__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "import os\n",
    "\n",
    "batch_size = 16\n",
    "epochs = 40\n",
    "\n",
    "img_rows = X_train[0].shape[0]\n",
    "img_cols = X_train[1].shape[0]\n",
    "input_size = (img_rows, img_cols, 3)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape = input_size), kernel_initializer=)\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss = 'binary_crossentropy',\n",
    "             optimizer = 'rmsprop',\n",
    "             metrics = ['accuracy'])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train,\n",
    "                   batch_size = batch_size,\n",
    "                   epochs = epochs,\n",
    "                   validation_data = (X_test, y_test),\n",
    "                   shuffle = True)\n",
    "\n",
    "model.save(\"cats_vs_dogs.h5\")\n",
    "\n",
    "scores = model.evaluate(X_test, y_test, verbose=1)\n",
    "print('Test loss', scores[0], 'Test accuracy', scores[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __Augmentation なし__\n",
    "\n",
    "Train on 10 samples, validate on 10 samples\n",
    "Epoch 1/25\n",
    "10/10 [==============================] - 0s 30ms/step - loss: 1.8070e-05 - acc: 1.0000 - val_loss: 3.0441 - val_acc: 0.6000\n",
    "Epoch 2/25\n",
    "10/10 [==============================] - 0s 26ms/step - loss: 2.1992e-06 - acc: 1.0000 - val_loss: 3.0435 - val_acc: 0.6000\n",
    "Epoch 3/25\n",
    "10/10 [==============================] - 0s 25ms/step - loss: 1.4173e-04 - acc: 1.0000 - val_loss: 3.0218 - val_acc: 0.7000\n",
    "Epoch 4/25\n",
    "10/10 [==============================] - 0s 26ms/step - loss: 9.7983e-07 - acc: 1.0000 - val_loss: 3.0216 - val_acc: 0.7000\n",
    "Epoch 5/25\n",
    "10/10 [==============================] - 0s 26ms/step - loss: 2.4776e-06 - acc: 1.0000 - val_loss: 3.0214 - val_acc: 0.7000\n",
    "Epoch 6/25\n",
    "10/10 [==============================] - 0s 25ms/step - loss: 4.4536e-06 - acc: 1.0000 - val_loss: 3.0208 - val_acc: 0.7000\n",
    "Epoch 7/25\n",
    "10/10 [==============================] - 0s 26ms/step - loss: 5.0711e-06 - acc: 1.0000 - val_loss: 3.0207 - val_acc: 0.7000\n",
    "Epoch 8/25\n",
    "10/10 [==============================] - 0s 26ms/step - loss: 4.0394e-06 - acc: 1.0000 - val_loss: 3.0207 - val_acc: 0.7000\n",
    "Epoch 9/25\n",
    "10/10 [==============================] - 0s 26ms/step - loss: 5.2048e-05 - acc: 1.0000 - val_loss: 3.0292 - val_acc: 0.7000\n",
    "Epoch 10/25\n",
    "10/10 [==============================] - 0s 25ms/step - loss: 3.3786e-06 - acc: 1.0000 - val_loss: 3.0292 - val_acc: 0.7000\n",
    "Epoch 11/25\n",
    "10/10 [==============================] - 0s 25ms/step - loss: 1.9690e-06 - acc: 1.0000 - val_loss: 3.0294 - val_acc: 0.7000\n",
    "Epoch 12/25\n",
    "10/10 [==============================] - 0s 25ms/step - loss: 1.0861e-04 - acc: 1.0000 - val_loss: 3.1017 - val_acc: 0.6000\n",
    "Epoch 13/25\n",
    "10/10 [==============================] - 0s 27ms/step - loss: 5.6698e-06 - acc: 1.0000 - val_loss: 3.1057 - val_acc: 0.6000\n",
    "Epoch 14/25\n",
    "10/10 [==============================] - 0s 26ms/step - loss: 0.0213 - acc: 1.0000 - val_loss: 2.2884 - val_acc: 0.6000\n",
    "Epoch 15/25\n",
    "10/10 [==============================] - 0s 25ms/step - loss: 0.0016 - acc: 1.0000 - val_loss: 2.7232 - val_acc: 0.5000\n",
    "Epoch 16/25\n",
    "10/10 [==============================] - 0s 25ms/step - loss: 0.0067 - acc: 1.0000 - val_loss: 2.9423 - val_acc: 0.6000\n",
    "Epoch 17/25\n",
    "10/10 [==============================] - 0s 26ms/step - loss: 4.8264e-04 - acc: 1.0000 - val_loss: 2.8328 - val_acc: 0.6000\n",
    "Epoch 18/25\n",
    "10/10 [==============================] - 0s 25ms/step - loss: 2.9219e-05 - acc: 1.0000 - val_loss: 2.8082 - val_acc: 0.6000\n",
    "Epoch 19/25\n",
    "10/10 [==============================] - 0s 25ms/step - loss: 5.6744e-04 - acc: 1.0000 - val_loss: 2.5338 - val_acc: 0.7000\n",
    "Epoch 20/25\n",
    "10/10 [==============================] - 0s 24ms/step - loss: 1.3732e-05 - acc: 1.0000 - val_loss: 2.5418 - val_acc: 0.7000\n",
    "Epoch 21/25\n",
    "10/10 [==============================] - 0s 24ms/step - loss: 1.1395e-04 - acc: 1.0000 - val_loss: 2.6436 - val_acc: 0.7000\n",
    "Epoch 22/25\n",
    "10/10 [==============================] - 0s 25ms/step - loss: 6.0817e-05 - acc: 1.0000 - val_loss: 2.7054 - val_acc: 0.7000\n",
    "Epoch 23/25\n",
    "10/10 [==============================] - 0s 24ms/step - loss: 0.0070 - acc: 1.0000 - val_loss: 3.6960 - val_acc: 0.6000\n",
    "Epoch 24/25\n",
    "10/10 [==============================] - 0s 23ms/step - loss: 0.0010 - acc: 1.0000 - val_loss: 4.0447 - val_acc: 0.6000\n",
    "Epoch 25/25\n",
    "10/10 [==============================] - 0s 24ms/step - loss: 1.5118e-04 - acc: 1.0000 - val_loss: 4.0725 - val_acc: 0.6000\n",
    "10/10 [==============================] - 0s 5ms/step\n",
    "Test loss 4.072466850280762 Test accuracy 0.6000000238418579"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __Augmentation 4 * 4__\n",
    "\n",
    "Train on 400 samples, validate on 80 samples\n",
    "Epoch 1/25\n",
    "400/400 [==============================] - 9s 21ms/step - loss: 0.7688 - acc: 0.4825 - val_loss: 0.6883 - val_acc: 0.5000\n",
    "Epoch 2/25\n",
    "400/400 [==============================] - 8s 20ms/step - loss: 0.7008 - acc: 0.5950 - val_loss: 0.6643 - val_acc: 0.6125\n",
    "Epoch 3/25\n",
    "400/400 [==============================] - 8s 19ms/step - loss: 0.6364 - acc: 0.6500 - val_loss: 0.5930 - val_acc: 0.7375\n",
    "Epoch 4/25\n",
    "400/400 [==============================] - 8s 19ms/step - loss: 0.6539 - acc: 0.6875 - val_loss: 0.6051 - val_acc: 0.7375\n",
    "Epoch 5/25\n",
    "400/400 [==============================] - 8s 19ms/step - loss: 0.5354 - acc: 0.7600 - val_loss: 0.5143 - val_acc: 0.7875\n",
    "Epoch 6/25\n",
    "400/400 [==============================] - 8s 20ms/step - loss: 0.5291 - acc: 0.7625 - val_loss: 0.5527 - val_acc: 0.6250\n",
    "Epoch 7/25\n",
    "400/400 [==============================] - 8s 20ms/step - loss: 0.4127 - acc: 0.8275 - val_loss: 0.3708 - val_acc: 0.8375\n",
    "Epoch 8/25\n",
    "400/400 [==============================] - 8s 19ms/step - loss: 0.3846 - acc: 0.8400 - val_loss: 0.4236 - val_acc: 0.8250\n",
    "Epoch 9/25\n",
    "400/400 [==============================] - 8s 19ms/step - loss: 0.3645 - acc: 0.8625 - val_loss: 0.3718 - val_acc: 0.8375\n",
    "Epoch 10/25\n",
    "400/400 [==============================] - 8s 19ms/step - loss: 0.2291 - acc: 0.9150 - val_loss: 0.3645 - val_acc: 0.8500\n",
    "Epoch 11/25\n",
    "400/400 [==============================] - 8s 19ms/step - loss: 0.2896 - acc: 0.8850 - val_loss: 0.3536 - val_acc: 0.8500\n",
    "Epoch 12/25\n",
    "400/400 [==============================] - 8s 20ms/step - loss: 0.2940 - acc: 0.8800 - val_loss: 0.3106 - val_acc: 0.8875\n",
    "Epoch 13/25\n",
    "400/400 [==============================] - 8s 20ms/step - loss: 0.1852 - acc: 0.9325 - val_loss: 0.3798 - val_acc: 0.8625\n",
    "Epoch 14/25\n",
    "400/400 [==============================] - 8s 20ms/step - loss: 0.1617 - acc: 0.9425 - val_loss: 0.4412 - val_acc: 0.8500\n",
    "Epoch 15/25\n",
    "400/400 [==============================] - 8s 19ms/step - loss: 0.1717 - acc: 0.9375 - val_loss: 0.3906 - val_acc: 0.8625\n",
    "Epoch 16/25\n",
    "400/400 [==============================] - 8s 20ms/step - loss: 0.1362 - acc: 0.9500 - val_loss: 0.3388 - val_acc: 0.9000\n",
    "Epoch 17/25\n",
    "400/400 [==============================] - 8s 20ms/step - loss: 0.0957 - acc: 0.9625 - val_loss: 0.3369 - val_acc: 0.8750\n",
    "Epoch 18/25\n",
    "400/400 [==============================] - 8s 20ms/step - loss: 0.1039 - acc: 0.9575 - val_loss: 0.6380 - val_acc: 0.8750\n",
    "Epoch 19/25\n",
    "400/400 [==============================] - 8s 20ms/step - loss: 0.1599 - acc: 0.9500 - val_loss: 1.1282 - val_acc: 0.8000\n",
    "Epoch 20/25\n",
    "400/400 [==============================] - 8s 20ms/step - loss: 0.0578 - acc: 0.9800 - val_loss: 0.5977 - val_acc: 0.8750\n",
    "Epoch 21/25\n",
    "400/400 [==============================] - 8s 19ms/step - loss: 0.1028 - acc: 0.9625 - val_loss: 0.5286 - val_acc: 0.8875\n",
    "Epoch 22/25\n",
    "400/400 [==============================] - 8s 19ms/step - loss: 0.0438 - acc: 0.9825 - val_loss: 0.8115 - val_acc: 0.8625\n",
    "Epoch 23/25\n",
    "400/400 [==============================] - 8s 20ms/step - loss: 0.0887 - acc: 0.9775 - val_loss: 0.6342 - val_acc: 0.8875\n",
    "Epoch 24/25\n",
    "400/400 [==============================] - 8s 19ms/step - loss: 0.0491 - acc: 0.9850 - val_loss: 0.5752 - val_acc: 0.8625\n",
    "Epoch 25/25\n",
    "400/400 [==============================] - 8s 19ms/step - loss: 0.1410 - acc: 0.9600 - val_loss: 0.6641 - val_acc: 0.8875\n",
    "80/80 [==============================] - 1s 7ms/step\n",
    "Test loss 0.6640982627868652 Test accuracy 0.8875"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('val_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('val_acc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __誤差と精度が上がり続ける__\n",
    "- 汎化誤差\n",
    "    - 学習時に使用しなかったデータに対する予測値と正解の差\n",
    "- クラス不均衡\n",
    "    - ではない\n",
    "- 正則化\n",
    "    - dropout\n",
    "    - 参考になりそう\n",
    "        - https://stackoverflow.com/questions/40910857/how-to-interpret-increase-in-both-loss-and-accuracy\n",
    "        - https://kharshit.github.io/blog/2018/12/07/loss-vs-accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- データオーグメンテーション\n",
    "    - lossを発生させて、勾配を発生させている?\n",
    "    - k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = [1, 2, 3]\n",
    "type(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
