{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __セルフレジ__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __試行__\n",
    "- __2019/07/07の現状__\n",
    "    - Predict速度の向上が必要\n",
    "        - Mobilenetの1層目から学習\n",
    "            - →　Predictが相当遅くなる\n",
    "        - Dense層1層のみを加え、学習する\n",
    "            - →　Predictの速度が向上し,5/6の正解\n",
    "        - Dense層を二層加え、Mobilenetの最後の層のみ学習\n",
    "            - →　14, 15, 16層以降のみ学習させたが、実のデータでの検証失敗\n",
    "            - → Mobile net層を一切学習せず、自作の層を三層追加したものの検証失敗\n",
    "        - Mobilenetの途中層から学習をしてみる\n",
    "            - 10層目からの学習 : ダメ\n",
    "            - 7 :　ダメ\n",
    "        - MobileNetは学習せず、Dense層のみ学習\n",
    "            - 128, 64, 32, 16, 8, 1, 全てDropout0.2\n",
    "                - だめ\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __試行__\n",
    "- 2019/07/08現状\n",
    "    - mobile[16~] + 8 + 1\n",
    "        - 0.81\n",
    "    - mobile[15~] + 8 + 1\n",
    "        - 0.72\n",
    "    - mobile[14~] + 8 + 1\n",
    "        - 0.8823529411764706\n",
    "    - mobile[14~] + 8 + 8 + 1\n",
    "        - 0.8823529411764706\n",
    "    - mobile[14~] + 16 + 8 + 1\n",
    "        - 0.8823529411764706\n",
    "    - mobile[13~] + 8 + 1\n",
    "        - 0.7058823529411765\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __試行__\n",
    "- 2019/07/09の現状\n",
    "    - acqueri\n",
    "    - soda\n",
    "    - cc_lemon\n",
    "    - fanta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_path = 'image_folder/images/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def augmentation(dir_path, initial_letter_of_file='w', augment_num=0):\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    note : 指定ディレクトリ内の,指定頭文字で始まるファイルを指定枚数オーグメントする\n",
    "    ----------\n",
    "    dir_path : フォルダパス\n",
    "    initial_letter : augmentしたいファイル名の頭文字\n",
    "    aument_num : augmentしたい枚数\n",
    "    ----------\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    files_name = [f for f in listdir(my_path) if isfile(join(my_path, f))]\n",
    "    files_name.remove('.DS_Store')\n",
    "    \n",
    "    \n",
    "    datagen = ImageDataGenerator(rotation_range=40,\n",
    "                             width_shift_range=0.2,\n",
    "                             #height_shift_range=0.2,\n",
    "                             shear_range=0.2,\n",
    "                             zoom_range=0.2,\n",
    "                             horizontal_flip=True,\n",
    "                             fill_mode='nearest'\n",
    "    )\n",
    "    \n",
    "    \n",
    "    for i, file in tqdm(enumerate(files_name)):\n",
    "        img = load_img(dir_path + file)\n",
    "        x = img_to_array(img)\n",
    "        x = x.reshape((1,) + x.shape) \n",
    "\n",
    "        if file[0] == initial_letter_of_file:\n",
    "            i = 0\n",
    "            for batch in datagen.flow(x, save_to_dir=dir_path, save_prefix=initial_letter_of_file, save_format=\"jpg\"):\n",
    "                i += 1\n",
    "                if i > augment_num:\n",
    "                    break\n",
    "\n",
    "        else:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "augmentation(my_path, 'c')\n",
    "augmentation(my_path, 'f')\n",
    "augmentation(my_path, 'l')\n",
    "augmentation(my_path, 'n')\n",
    "augmentation(my_path, 's')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __正規分布のノイズを入れる__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import *\n",
    "from keras.preprocessing.image import load_img, img_to_array, array_to_img\n",
    "import cv2\n",
    "\n",
    "import datetime\n",
    "\n",
    "\n",
    "def add_noise(my_path='image_folder/images/', iter_num=1):\n",
    "    \n",
    "    size = 224\n",
    "\n",
    "    files_name = [f for f in listdir(my_path) if isfile(join(my_path, f))]\n",
    "    files_name.remove('.DS_Store')\n",
    "\n",
    "    for _ in range(iter_num):\n",
    "        for file in files_name:\n",
    "            image = cv2.imread(my_path + file)\n",
    "            image = cv2.resize(image, (size, size), interpolation = cv2.INTER_AREA)\n",
    "            image = image + rand(image.shape[1], image.shape[2])/10\n",
    "            #x = x.reshape((1,) + x.shape)\n",
    "            cv2.imwrite(my_path + file[0:6] + str(datetime.datetime.now().time())[-4:] +'.jpg', image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_noise()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_name = [f for f in listdir(my_path) if isfile(join(my_path, f))]\n",
    "files_name.remove('.DS_Store')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __前処理__\n",
    "- ラベルデータの保存\n",
    "- resize\n",
    "- test_data, val_dataへの分割\n",
    "- Dog - 1, Cat - 0\n",
    "- ディレクトリの作成\n",
    "    - catsvsdogs / images / train / dogs\n",
    "    - catsvsdogs / images / train / cats\n",
    "    - catsvsdogs / images / val / dogs\n",
    "    - catsvsdogs / images / val / cats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __保存用ディレクトリの作成__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "class0_dir_train = 'image_folder/train/class0/'\n",
    "class0_dir_val = 'image_folder/test/class0/'\n",
    "\n",
    "class1_dir_train = 'image_folder/train/class1/'\n",
    "class1_dir_val = 'image_folder/test/class1/'\n",
    "\n",
    "class2_dir_train = 'image_folder/train/class2/'\n",
    "class2_dir_val = 'image_folder/test/class2/'\n",
    "\n",
    "class3_dir_train = 'image_folder/train/class3/'\n",
    "class3_dir_val = 'image_folder/test/class3/'\n",
    "\n",
    "class4_dir_train = 'image_folder/train/class4/'\n",
    "class4_dir_val = 'image_folder/test/class4/'\n",
    "\n",
    "def make_dir(directory):\n",
    "    if os.path.exists(directory):\n",
    "        shutil.rmtree(directory)\n",
    "    os.makedirs(directory)\n",
    "    \n",
    "make_dir(class0_dir_train)\n",
    "make_dir(class0_dir_val)\n",
    "\n",
    "make_dir(class1_dir_train)\n",
    "make_dir(class1_dir_val)\n",
    "\n",
    "make_dir(class2_dir_train)\n",
    "make_dir(class2_dir_val)\n",
    "\n",
    "make_dir(class3_dir_train)\n",
    "make_dir(class3_dir_val)\n",
    "\n",
    "make_dir(class4_dir_train)\n",
    "make_dir(class4_dir_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __データのふるい分け、分割__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import sys\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def train_test_split(files_name, class_0='c', class_1='f', class_2='l', class_3='n', class_4='s' ,train_size=0.8):\n",
    "    \n",
    "    \"\"\"\n",
    "    note : 画像フォルダから、指定クラスを、指定割合でtrain_sprit\n",
    "    ----------\n",
    "    class_0 : クラス名（今回はwilkinson）\n",
    "    class_1 : クラス名（今回はcoffee）\n",
    "    train_size : 分割したい割合\n",
    "    ----------\n",
    "    \"\"\"\n",
    "    \n",
    "    class_0_count = 0\n",
    "    class_1_count = 0\n",
    "    class_2_count = 0\n",
    "    class_3_count = 0\n",
    "    class_4_count = 0\n",
    "    \n",
    "    each_class_size = len(files_name) // 5\n",
    "    \n",
    "    train_size = each_class_size * train_size\n",
    "    test_size = each_class_size - train_size\n",
    "    \n",
    "    training_images = []\n",
    "    training_labels = []\n",
    "    test_images = []\n",
    "    test_labels = []\n",
    "    training_file_name = []\n",
    "    test_file_name = []\n",
    "    \n",
    "    size=224\n",
    "    \n",
    "    for i, file in tqdm(enumerate(files_name)):\n",
    "        \n",
    "        if files_name[i][0] == class_0:\n",
    "            class_0_count += 1\n",
    "            image = cv2.imread(my_path + file)\n",
    "            image = cv2.resize(image, (size, size), interpolation = cv2.INTER_AREA)\n",
    "            if class_0_count <= train_size:\n",
    "                training_images.append(image)\n",
    "                training_labels.append(0)\n",
    "                training_file_name.append(file)\n",
    "                cv2.imwrite(class0_dir_train + class_0 + str(class_0_count) + '.jpg', image)\n",
    "            if class_0_count > train_size and class_0_count <= train_size + test_size:\n",
    "                test_images.append(image)\n",
    "                test_labels.append(0)\n",
    "                test_file_name.append(file)\n",
    "                cv2.imwrite(class0_dir_val + class_0 + str(class_0_count) + '_' + '.jpg', image)\n",
    "\n",
    "                \n",
    "        if files_name[i][0] == class_1:\n",
    "            class_1_count += 1\n",
    "            image = cv2.imread(my_path + file)\n",
    "            image = cv2.resize(image, (size, size), interpolation = cv2.INTER_AREA)\n",
    "            if class_1_count <= train_size:\n",
    "                training_images.append(image)\n",
    "                training_labels.append(1)\n",
    "                training_file_name.append(file)\n",
    "                cv2.imwrite(class1_dir_train + class_1 + str(class_1_count) + '.jpg', image)\n",
    "            if class_1_count > train_size and class_1_count <= train_size + test_size:\n",
    "                test_images.append(image)\n",
    "                test_labels.append(1)\n",
    "                test_file_name.append(file)\n",
    "                cv2.imwrite(class1_dir_val + class_1 + str(class_1_count) + '_' + '.jpg', image)\n",
    "                \n",
    "                \n",
    "        if files_name[i][0] == class_2:\n",
    "            class_2_count += 1\n",
    "            image = cv2.imread(my_path + file)\n",
    "            image = cv2.resize(image, (size, size), interpolation = cv2.INTER_AREA)\n",
    "            if class_2_count <= train_size:\n",
    "                training_images.append(image)\n",
    "                training_labels.append(2)\n",
    "                training_file_name.append(file)\n",
    "                cv2.imwrite(class2_dir_train + class_2 + str(class_2_count) + '.jpg', image)\n",
    "            if class_2_count > train_size and class_2_count <= train_size + test_size:\n",
    "                test_images.append(image)\n",
    "                test_labels.append(2)\n",
    "                test_file_name.append(file)\n",
    "                cv2.imwrite(class2_dir_val + class_2 + str(class_2_count) + '_' + '.jpg', image)\n",
    "                \n",
    "                \n",
    "        if files_name[i][0] == class_3:\n",
    "            class_3_count += 1\n",
    "            image = cv2.imread(my_path + file)\n",
    "            image = cv2.resize(image, (size, size), interpolation = cv2.INTER_AREA)\n",
    "            if class_3_count <= train_size:\n",
    "                training_images.append(image)\n",
    "                training_labels.append(3)\n",
    "                training_file_name.append(file)\n",
    "                cv2.imwrite(class3_dir_train + class_3 + str(class_3_count) + '.jpg', image)\n",
    "            if class_3_count > train_size and class_3_count <= train_size + test_size:\n",
    "                test_images.append(image)\n",
    "                test_labels.append(3)\n",
    "                test_file_name.append(file)\n",
    "                cv2.imwrite(class3_dir_val + class_3 + str(class_3_count) + '_' + '.jpg', image)\n",
    "                \n",
    "                \n",
    "        if files_name[i][0] == class_4:\n",
    "            class_4_count += 1\n",
    "            image = cv2.imread(my_path + file)\n",
    "            image = cv2.resize(image, (size, size), interpolation = cv2.INTER_AREA)\n",
    "            if class_4_count <= train_size:\n",
    "                training_images.append(image)\n",
    "                training_labels.append(4)\n",
    "                training_file_name.append(file)\n",
    "                cv2.imwrite(class4_dir_train + class_4 + str(class_4_count) + '.jpg', image)\n",
    "            if class_4_count > train_size and class_4_count <= train_size + test_size:\n",
    "                test_images.append(image)\n",
    "                test_labels.append(4)\n",
    "                test_file_name.append(file)\n",
    "                cv2.imwrite(class4_dir_val + class_4 + str(class_4_count) + '_' + '.jpg', image)\n",
    "                \n",
    "    return training_images, training_labels, test_images, test_labels, training_file_name, test_file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "954it [00:01, 534.54it/s]\n"
     ]
    }
   ],
   "source": [
    "training_images, training_labels, test_images, test_labels, training_file_name, test_file_name = train_test_split(files_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['soda_f1595.jpg',\n",
       " 'cocaco1034.jpg',\n",
       " 'fanta_1059.jpg',\n",
       " 'cocaco6773.jpg',\n",
       " 'fanta_9834.jpg',\n",
       " 'lemon_2196.jpg',\n",
       " 'cocaco9859.jpg',\n",
       " 'fanta_1529.jpg',\n",
       " 'fanta_0145.jpg',\n",
       " 'fanta_9161.jpg',\n",
       " 'cocaco9130.jpg',\n",
       " 'cocaco4401.jpg',\n",
       " 'soda_f2512.jpg',\n",
       " 'namach9470.jpg',\n",
       " 'lemon_7004.jpg']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_file_name[20:35]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4, 0, 1, 0, 1, 2, 0, 1, 1, 1, 0, 0, 4, 3, 2]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_labels[20:35]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_num = 4\n",
    "columns = class_num + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __Kerasが対応するファイル型に変換__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez('multi_classifier_training_data.npz', np.array(training_images))\n",
    "np.savez('multi_classifier_training_labels.npz', np.identity(columns)[training_labels])\n",
    "np.savez('multi_classifier_test_data.npz', np.array(test_images))\n",
    "np.savez('multi_classifier_test_labels.npz', np.identity(columns)[test_labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def load_data_training_and_test(datasetname):\n",
    "    npzfile = np.load(datasetname + \"_training_data.npz\")\n",
    "    train = npzfile[\"arr_0\"]\n",
    "    \n",
    "    npzfile = np.load(datasetname + \"_training_labels.npz\")\n",
    "    train_labels = npzfile[\"arr_0\"]\n",
    "    \n",
    "    npzfile = np.load(datasetname + \"_test_data.npz\")\n",
    "    test = npzfile[\"arr_0\"]\n",
    "    \n",
    "    npzfile = np.load(datasetname + \"_test_labels.npz\")\n",
    "    test_labels = npzfile[\"arr_0\"]\n",
    "    \n",
    "    return (train, train_labels), (test, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for i in range(1, 11):\n",
    "    random = np.random.randint(0, len(training_images))\n",
    "    cv2.imshow(\"image_\" + str(i), training_images[random])\n",
    "    if training_labels[random] == 0:\n",
    "        print(str(i) + \"- Cat\")\n",
    "    else:\n",
    "        print(str(i) + \"- Dog\")\n",
    "        \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __データの前処理__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = load_data_training_and_test(\"multi_classifier\")\n",
    "\n",
    "y_train = y_train.reshape(y_train.shape[0], columns)\n",
    "y_test = y_test.reshape(y_test.shape[0], columns)\n",
    "\n",
    "X_train = X_train.astype(\"float32\")\n",
    "X_test = X_test.astype(\"float32\")\n",
    "\n",
    "X_train /= 255\n",
    "X_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "188"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __学習__\n",
    "- 自作の層で学習を行なったが、精度が低い"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------------\n",
      "This code was runned on date / time below 2019/07/10 22:29:22\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "import os\n",
    "\n",
    "batch_size = 16\n",
    "epochs = 8\n",
    "\n",
    "img_rows = X_train[0].shape[0]\n",
    "img_cols = X_train[1].shape[0]\n",
    "input_size = (224, 224, 3)\n",
    "\n",
    "\"\"\"\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, 3, 3, border_mode='same', input_shape=input_size))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Conv2D(32, 3, 3))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), border_mode=(\"same\")))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(200))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(200))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(3))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "print('---------------------------')\n",
    "\n",
    "\"\"\"\"\"\"\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), input_shape = input_size))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(32))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(32))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(32))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "from keras.applications.mobilenet_v2 import MobileNetV2\n",
    "\n",
    "conv_base = MobileNetV2(weights='imagenet', include_top=False, input_shape=input_size)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(conv_base)\n",
    "\n",
    "\"\"\"\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(32))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(32))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(16))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\"\"\"\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(16))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(8))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(5))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "\n",
    "set_trainable = False\n",
    "for layer in conv_base.layers:\n",
    "    if layer.name == 'block_16_expand':\n",
    "        # 一切の学習を行わない場合\n",
    "        set_trainable = False\n",
    "    if set_trainable:\n",
    "        layer.trainable = True\n",
    "    else:\n",
    "        layer.trainable = False\n",
    "\n",
    "    \n",
    "\"\"\"\n",
    "for layer in conv_base__.layers:\n",
    "    print(layer.name, ':', layer.trainable)\n",
    "\"\"\"\n",
    "\n",
    "model.compile(loss = 'categorical_crossentropy',\n",
    "             optimizer = 'adam',\n",
    "             metrics = ['accuracy'])\n",
    "\n",
    "\n",
    "# どこまで実行しているか不明になるので...\n",
    "from datetime import datetime\n",
    "print('--------------------------------------------------------------------------------------')\n",
    "print('This code was runned on date / time below', datetime.now().strftime(\"%Y/%m/%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_1 : False\n",
      "Conv1_pad : False\n",
      "Conv1 : False\n",
      "bn_Conv1 : False\n",
      "Conv1_relu : False\n",
      "expanded_conv_depthwise : False\n",
      "expanded_conv_depthwise_BN : False\n",
      "expanded_conv_depthwise_relu : False\n",
      "expanded_conv_project : False\n",
      "expanded_conv_project_BN : False\n",
      "block_1_expand : False\n",
      "block_1_expand_BN : False\n",
      "block_1_expand_relu : False\n",
      "block_1_pad : False\n",
      "block_1_depthwise : False\n",
      "block_1_depthwise_BN : False\n",
      "block_1_depthwise_relu : False\n",
      "block_1_project : False\n",
      "block_1_project_BN : False\n",
      "block_2_expand : False\n",
      "block_2_expand_BN : False\n",
      "block_2_expand_relu : False\n",
      "block_2_depthwise : False\n",
      "block_2_depthwise_BN : False\n",
      "block_2_depthwise_relu : False\n",
      "block_2_project : False\n",
      "block_2_project_BN : False\n",
      "block_2_add : False\n",
      "block_3_expand : False\n",
      "block_3_expand_BN : False\n",
      "block_3_expand_relu : False\n",
      "block_3_pad : False\n",
      "block_3_depthwise : False\n",
      "block_3_depthwise_BN : False\n",
      "block_3_depthwise_relu : False\n",
      "block_3_project : False\n",
      "block_3_project_BN : False\n",
      "block_4_expand : False\n",
      "block_4_expand_BN : False\n",
      "block_4_expand_relu : False\n",
      "block_4_depthwise : False\n",
      "block_4_depthwise_BN : False\n",
      "block_4_depthwise_relu : False\n",
      "block_4_project : False\n",
      "block_4_project_BN : False\n",
      "block_4_add : False\n",
      "block_5_expand : False\n",
      "block_5_expand_BN : False\n",
      "block_5_expand_relu : False\n",
      "block_5_depthwise : False\n",
      "block_5_depthwise_BN : False\n",
      "block_5_depthwise_relu : False\n",
      "block_5_project : False\n",
      "block_5_project_BN : False\n",
      "block_5_add : False\n",
      "block_6_expand : False\n",
      "block_6_expand_BN : False\n",
      "block_6_expand_relu : False\n",
      "block_6_pad : False\n",
      "block_6_depthwise : False\n",
      "block_6_depthwise_BN : False\n",
      "block_6_depthwise_relu : False\n",
      "block_6_project : False\n",
      "block_6_project_BN : False\n",
      "block_7_expand : False\n",
      "block_7_expand_BN : False\n",
      "block_7_expand_relu : False\n",
      "block_7_depthwise : False\n",
      "block_7_depthwise_BN : False\n",
      "block_7_depthwise_relu : False\n",
      "block_7_project : False\n",
      "block_7_project_BN : False\n",
      "block_7_add : False\n",
      "block_8_expand : False\n",
      "block_8_expand_BN : False\n",
      "block_8_expand_relu : False\n",
      "block_8_depthwise : False\n",
      "block_8_depthwise_BN : False\n",
      "block_8_depthwise_relu : False\n",
      "block_8_project : False\n",
      "block_8_project_BN : False\n",
      "block_8_add : False\n",
      "block_9_expand : False\n",
      "block_9_expand_BN : False\n",
      "block_9_expand_relu : False\n",
      "block_9_depthwise : False\n",
      "block_9_depthwise_BN : False\n",
      "block_9_depthwise_relu : False\n",
      "block_9_project : False\n",
      "block_9_project_BN : False\n",
      "block_9_add : False\n",
      "block_10_expand : False\n",
      "block_10_expand_BN : False\n",
      "block_10_expand_relu : False\n",
      "block_10_depthwise : False\n",
      "block_10_depthwise_BN : False\n",
      "block_10_depthwise_relu : False\n",
      "block_10_project : False\n",
      "block_10_project_BN : False\n",
      "block_11_expand : False\n",
      "block_11_expand_BN : False\n",
      "block_11_expand_relu : False\n",
      "block_11_depthwise : False\n",
      "block_11_depthwise_BN : False\n",
      "block_11_depthwise_relu : False\n",
      "block_11_project : False\n",
      "block_11_project_BN : False\n",
      "block_11_add : False\n",
      "block_12_expand : False\n",
      "block_12_expand_BN : False\n",
      "block_12_expand_relu : False\n",
      "block_12_depthwise : False\n",
      "block_12_depthwise_BN : False\n",
      "block_12_depthwise_relu : False\n",
      "block_12_project : False\n",
      "block_12_project_BN : False\n",
      "block_12_add : False\n",
      "block_13_expand : False\n",
      "block_13_expand_BN : False\n",
      "block_13_expand_relu : False\n",
      "block_13_pad : False\n",
      "block_13_depthwise : False\n",
      "block_13_depthwise_BN : False\n",
      "block_13_depthwise_relu : False\n",
      "block_13_project : False\n",
      "block_13_project_BN : False\n",
      "block_14_expand : False\n",
      "block_14_expand_BN : False\n",
      "block_14_expand_relu : False\n",
      "block_14_depthwise : False\n",
      "block_14_depthwise_BN : False\n",
      "block_14_depthwise_relu : False\n",
      "block_14_project : False\n",
      "block_14_project_BN : False\n",
      "block_14_add : False\n",
      "block_15_expand : False\n",
      "block_15_expand_BN : False\n",
      "block_15_expand_relu : False\n",
      "block_15_depthwise : False\n",
      "block_15_depthwise_BN : False\n",
      "block_15_depthwise_relu : False\n",
      "block_15_project : False\n",
      "block_15_project_BN : False\n",
      "block_15_add : False\n",
      "block_16_expand : False\n",
      "block_16_expand_BN : False\n",
      "block_16_expand_relu : False\n",
      "block_16_depthwise : False\n",
      "block_16_depthwise_BN : False\n",
      "block_16_depthwise_relu : False\n",
      "block_16_project : False\n",
      "block_16_project_BN : False\n",
      "Conv_1 : False\n",
      "Conv_1_bn : False\n",
      "out_relu : False\n",
      "--------------------------------------------------------------------------------------\n",
      "This code was runned on date / time below 2019/07/10 22:29:22\n"
     ]
    }
   ],
   "source": [
    "for layer in conv_base.layers:\n",
    "    print(layer.name, ':', layer.trainable)\n",
    "    \n",
    "# どこまで実行しているか不明になるので...\n",
    "from datetime import datetime\n",
    "print('--------------------------------------------------------------------------------------')\n",
    "print('This code was runned on date / time below', datetime.now().strftime(\"%Y/%m/%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "mobilenetv2_1.00_224 (Model) (None, 7, 7, 1280)        2257984   \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 62720)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                1003536   \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 5)                 45        \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 3,261,701\n",
      "Trainable params: 1,003,717\n",
      "Non-trainable params: 2,257,984\n",
      "_________________________________________________________________\n",
      "--------------------------------------------------------------------------------------\n",
      "This code was runned on date / time below 2019/07/10 22:29:22\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n",
    "\n",
    "# どこまで実行しているか不明になるので...\n",
    "from datetime import datetime\n",
    "print('--------------------------------------------------------------------------------------')\n",
    "print('This code was runned on date / time below', datetime.now().strftime(\"%Y/%m/%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 760 samples, validate on 188 samples\n",
      "Epoch 1/10\n",
      "760/760 [==============================] - 42s 56ms/step - loss: 2.2298 - acc: 0.4053 - val_loss: 0.8545 - val_acc: 0.6543\n",
      "Epoch 2/10\n",
      "760/760 [==============================] - 37s 49ms/step - loss: 1.0047 - acc: 0.5276 - val_loss: 0.7609 - val_acc: 0.7500\n",
      "Epoch 3/10\n",
      "760/760 [==============================] - 37s 49ms/step - loss: 0.9454 - acc: 0.6513 - val_loss: 0.7218 - val_acc: 0.8085\n",
      "Epoch 4/10\n",
      "760/760 [==============================] - 37s 49ms/step - loss: 0.8843 - acc: 0.6816 - val_loss: 0.6754 - val_acc: 0.8085\n",
      "Epoch 5/10\n",
      "760/760 [==============================] - 37s 49ms/step - loss: 0.8948 - acc: 0.6592 - val_loss: 0.6452 - val_acc: 0.8085\n",
      "Epoch 6/10\n",
      "760/760 [==============================] - 37s 49ms/step - loss: 0.8138 - acc: 0.6803 - val_loss: 0.6040 - val_acc: 0.8085\n",
      "Epoch 7/10\n",
      "760/760 [==============================] - 38s 49ms/step - loss: 0.7764 - acc: 0.6908 - val_loss: 0.5777 - val_acc: 0.8085\n",
      "Epoch 8/10\n",
      "760/760 [==============================] - 37s 49ms/step - loss: 0.8347 - acc: 0.6697 - val_loss: 0.5692 - val_acc: 0.8085\n",
      "Epoch 9/10\n",
      "760/760 [==============================] - 39s 51ms/step - loss: 0.8137 - acc: 0.6605 - val_loss: 0.5518 - val_acc: 0.8085\n",
      "Epoch 10/10\n",
      "760/760 [==============================] - 39s 51ms/step - loss: 0.7790 - acc: 0.6632 - val_loss: 0.5373 - val_acc: 0.8085\n",
      "188/188 [==============================] - 9s 49ms/step\n",
      "Test loss 0.5373443872370618 Test accuracy 0.8085106408342402\n",
      "--------------------------------------------------------------------------------------\n",
      "This code was runned on date / time below 2019/07/10 22:35:55\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train,\n",
    "                   batch_size = batch_size,\n",
    "                   epochs = 10,\n",
    "                   validation_data = (X_test, y_test),\n",
    "                   shuffle = True)\n",
    "\n",
    "# 再構築可能なモデルの構造\n",
    "# モデルの重み\n",
    "# 学習時の設定 (loss，optimizer)\n",
    "# optimizerの状態．これにより，学習を終えた時点から正確に学習を再開できます\n",
    "\n",
    "model.save(\"multi_label.h5\")\n",
    "scores = model.evaluate(X_test, y_test, verbose=1)\n",
    "\n",
    "print('Test loss', scores[0], 'Test accuracy', scores[1])\n",
    "\n",
    "# どこまで実行しているか不明になるので...\n",
    "from datetime import datetime\n",
    "print('--------------------------------------------------------------------------------------')\n",
    "print('This code was runned on date / time below', datetime.now().strftime(\"%Y/%m/%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __可視化__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------------\n",
      "This code was runned on date / time below 2019/07/10 22:35:55\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('val_loss')\n",
    "\n",
    "# どこまで実行しているか不明になるので...\n",
    "from datetime import datetime\n",
    "print('--------------------------------------------------------------------------------------')\n",
    "print('This code was runned on date / time below', datetime.now().strftime(\"%Y/%m/%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------------\n",
      "This code was runned on date / time below 2019/07/10 22:35:55\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('val_acc')\n",
    "\n",
    "# どこまで実行しているか不明になるので...\n",
    "from datetime import datetime\n",
    "print('--------------------------------------------------------------------------------------')\n",
    "print('This code was runned on date / time below', datetime.now().strftime(\"%Y/%m/%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __学習済みモデルのpredict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------------\n",
      "result prob :  soda_float / image :  test_image/lemon__20190709193708.jpg\n",
      "file name : lemon__20190709193708.jpg / class name : soda_float\n",
      "×\n",
      "--------------------------------------------------------------------------------------\n",
      "result prob :  cocacola / image :  test_image/fanta_litchi__20190709194117.jpg\n",
      "file name : fanta_litchi__20190709194117.jpg / class name : cocacola\n",
      "×\n",
      "--------------------------------------------------------------------------------------\n",
      "result prob :  lemon / image :  test_image/lemon__20190709193656.jpg\n",
      "file name : lemon__20190709193656.jpg / class name : lemon\n",
      "○\n",
      "--------------------------------------------------------------------------------------\n",
      "result prob :  namacha / image :  test_image/namacha__20190709194420.jpg\n",
      "file name : namacha__20190709194420.jpg / class name : namacha\n",
      "○\n",
      "--------------------------------------------------------------------------------------\n",
      "result prob :  cocacola / image :  test_image/fanta_litchi__20190709194107.jpg\n",
      "file name : fanta_litchi__20190709194107.jpg / class name : cocacola\n",
      "×\n",
      "--------------------------------------------------------------------------------------\n",
      "result prob :  soda_float / image :  test_image/soda_float__20190709194702.jpg\n",
      "file name : soda_float__20190709194702.jpg / class name : soda_float\n",
      "○\n",
      "--------------------------------------------------------------------------------------\n",
      "result prob :  soda_float / image :  test_image/soda_float__20190709194655.jpg\n",
      "file name : soda_float__20190709194655.jpg / class name : soda_float\n",
      "○\n",
      "--------------------------------------------------------------------------------------\n",
      "result prob :  cocacola / image :  test_image/cocacola__20190709192937.jpg\n",
      "file name : cocacola__20190709192937.jpg / class name : cocacola\n",
      "○\n",
      "--------------------------------------------------------------------------------------\n",
      "result prob :  cocacola / image :  test_image/cocacola__20190709192925.jpg\n",
      "file name : cocacola__20190709192925.jpg / class name : cocacola\n",
      "○\n",
      "--------------------------------------------------------------------------------------\n",
      "result prob :  namacha / image :  test_image/namacha__20190709194403.jpg\n",
      "file name : namacha__20190709194403.jpg / class name : namacha\n",
      "○\n",
      "--------------------------------------------------------------------------------------\n",
      "正解数は10サンプル中7で、testデータの正解率は0.7です。\n",
      "--------------------------------------------------------------------------------------\n",
      "画像ごとの処理時間(秒) : 0.1762158155441284\n",
      "--------------------------------------------------------------------------------------\n",
      "This code was runned on date / time below 2019/07/10 22:36:14\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from keras.models import load_model\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import time\n",
    "\n",
    "\n",
    "class predict_class:\n",
    "    \n",
    "    def __init__(self, model='multi_label.h5', test_image_path='test_image/'):\n",
    "        \"\"\"\n",
    "        attribute\n",
    "        ----------------\n",
    "        model : model(.h5)\n",
    "        test_image_path : テストファイルが入っているディレクトリ\n",
    "        \"\"\"\n",
    "        self.model = load_model(model)\n",
    "        self.test_image_path = test_image_path\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    def predict(self, image, class_0='cocacola', class_1='fanta_litchi', class_2='lemon', class_3='namacha', class_4='soda_float'):\n",
    "        \"\"\"\n",
    "        note : 与えられたimageのpathから、多値分類を行う関数\n",
    "        ----------------\n",
    "        attribute\n",
    "        image : image画像のパス\n",
    "        ----------------\n",
    "        \"\"\"\n",
    "        class_name = [class_0, class_1, class_2, class_3, class_4]\n",
    "        sample = load_img(image, target_size=(224,224))\n",
    "        sample_arr = img_to_array(sample)\n",
    "        sample_arr = np.expand_dims(sample_arr, axis=0)\n",
    "        sample_arr = sample_arr /255\n",
    "        result = self.model.predict(sample_arr)\n",
    "        print('result prob : ', class_name[np.argmax(result)], '/ image : ', image)\n",
    "        return class_name[np.argmax(result)]\n",
    "\n",
    "        \n",
    "    def accuracy_check(self):\n",
    "        \"\"\"\n",
    "        note : test_imageディレクトリ内の複数のテストデータで、モデルの精度判定する関数\n",
    "        ---------------\n",
    "        \"\"\"\n",
    "        print('--------------------------------------------------------------------------------------')\n",
    "        # 時間計測（start）\n",
    "        start = time.time()\n",
    "\n",
    "        # 画像ファイルの取り出し\n",
    "        test_images = [f for f in listdir(self.test_image_path) if isfile(join(self.test_image_path, f))]\n",
    "        test_images.remove('.DS_Store')\n",
    "\n",
    "        collect = 0\n",
    "        for test_image in test_images:\n",
    "            class_name = self.predict(self.test_image_path + test_image)\n",
    "            print('file name :', test_image, '/ class name :', class_name)\n",
    "            if test_image[0] == class_name[0]:\n",
    "                print('○')\n",
    "                collect += 1\n",
    "            else:\n",
    "                print('×')\n",
    "            print('--------------------------------------------------------------------------------------')\n",
    "\n",
    "\n",
    "        print('正解数は{sample}サンプル中{collect}で、testデータの正解率は{rate}です。'.format(sample=len(test_images),\n",
    "                                                                        collect=collect,\n",
    "                                                                        rate=collect/len(test_images)))\n",
    "        print('--------------------------------------------------------------------------------------')\n",
    "\n",
    "        # 時間計測（end）\n",
    "        elapsed_time = time.time() - start\n",
    "        #print('合計秒数:：',elapsed_time)\n",
    "        print('画像ごとの処理時間(秒) :', str((elapsed_time)/len(test_images)) )\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    # インスタンスの作成\n",
    "    predict = predict_class()\n",
    "    \n",
    "    # テストファイルのパスフォルダ名\n",
    "    test_image_path = 'test_image/'\n",
    "\n",
    "    #predict.predict(test_image_path + 'aquarius__20190709160943.jpg')\n",
    "    predict.accuracy_check()\n",
    "    \n",
    "    # どこまで実行しているか不明になるので...\n",
    "    from datetime import datetime\n",
    "    print('--------------------------------------------------------------------------------------')\n",
    "    print('This code was runned on date / time below', datetime.now().strftime(\"%Y/%m/%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __中間層におけるロジットの出力__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import time\n",
    "\n",
    "from keras.models import Model\n",
    "\n",
    "\n",
    "def output_logit(layer_name='dense_6', test_image_path='test_imageのコピー/'):\n",
    "    \"\"\"\n",
    "    note : 特定層においてロジットの出力をarrayにて出力する関数\n",
    "    ----------\n",
    "    attribute\n",
    "    layer_name : layer\n",
    "    test_image_path : test_image(predictする画像)が格納されているフォルダ\n",
    "    \"\"\"\n",
    "    # 画像ファイルの取り出し\n",
    "    test_images = [f for f in listdir(test_image_path) if isfile(join(test_image_path, f))]\n",
    "    test_images.remove('.DS_Store')\n",
    "    \n",
    "    hidden_layer_model = Model(inputs=model.input, outputs=model.get_layer(layer_name).output)\n",
    "    \n",
    "    for test_image in test_images:\n",
    "    \n",
    "        img = cv2.imread(test_image_path + test_image)\n",
    "        img = cv2.resize(img, (224, 224))\n",
    "        target = np.reshape(img, (1, img.shape[0], img.shape[1], img.shape[2])).astype('float') / 255.0\n",
    "        array = hidden_layer_model.predict(target)\n",
    "        print('file_name :', test_image)\n",
    "        print('array :', array)\n",
    "        print('std :', np.std(array), 'var :', np.var(array))\n",
    "        print('--------------------------------------------------------------------------------------')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No such layer: dense_6",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-57296a6feadd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0moutput_logit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# class_0='cocacola', class_1='fanta_litchi', class_2='lemon', class_3='namacha', class_4='soda_float'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-23-256af63df25f>\u001b[0m in \u001b[0;36moutput_logit\u001b[0;34m(layer_name, test_image_path)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mtest_images\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.DS_Store'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mhidden_layer_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mtest_image\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_images\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/network.py\u001b[0m in \u001b[0;36mget_layer\u001b[0;34m(self, name, index)\u001b[0m\n\u001b[1;32m    356\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 358\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'No such layer: '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: No such layer: dense_6"
     ]
    }
   ],
   "source": [
    "output_logit()\n",
    "# class_0='cocacola', class_1='fanta_litchi', class_2='lemon', class_3='namacha', class_4='soda_float'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __VGG16__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.vgg16 import VGG16, decode_predictions\n",
    "\n",
    "model_vgg16 = VGG16(include_top=True, weights='imagenet')\n",
    "#model_vgg16.summary()\n",
    "\n",
    "import cv2\n",
    "from keras.models import load_model\n",
    "\n",
    "def predict_class_vgg16(image):\n",
    "    sample = load_img(image, target_size=(224,224))\n",
    "    print(sample)\n",
    "    sample_arr = img_to_array(sample)\n",
    "    sample_arr = np.expand_dims(sample_arr, axis=0)\n",
    "    result = model_vgg16.predict(sample_arr)\n",
    "    print(decode_predictions(result, top=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_class(path_name):\n",
    "\n",
    "    test_images = [f for f in listdir(test_image_path) if isfile(join(test_image_path, f))]\n",
    "    test_images.remove('.DS_Store')\n",
    "    \n",
    "    for test_image in test_images:\n",
    "        print(test_image)\n",
    "        predict_class_vgg16(test_image_path + test_image)\n",
    "        print('--------------------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_class(test_image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.vgg16 import VGG16, decode_predictions\n",
    "model_vgg16 = VGG16(include_top=True, weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_vgg16.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_base.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
